
#for LLM type openai needs the openai api key, if you want to use ollama just put "local" in LLM_TYPE
LLM_TYPE="local"
OPENAI_API_KEY=''
#this is where you specify LLM models. The primary model must be able to use tools, if you dont select a secondary model, which is used for creative writing, it will default to the primary
##Ollama
LOCAL_MODEL = "granite3-dense"
LOCAL_MODEL2 = "gemma2:2b"
##OpenAI
OPENAI_MODEL= "gpt-4o-mini"
OPENAI_MODEL2 = "gpt-4o"
#this is the default url for ollama, change this as needed
OLLAMA_URL="http://localhost:11434"
